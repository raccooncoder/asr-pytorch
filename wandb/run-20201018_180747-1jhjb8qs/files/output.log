cuda:0
/home/raccooncoder/.venv/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  
Train Epoch: 0 [3840/11775 (33%)]	Loss: 7.279771
Train Epoch: 0 [7680/11775 (65%)]	Loss: 2.881837
Train Epoch: 0 [11520/11775 (98%)]	Loss: 2.747996

Train Epoch: 1 [3840/11775 (33%)]	Loss: 2.730930
Train Epoch: 1 [7680/11775 (65%)]	Loss: 2.727140
Train Epoch: 1 [11520/11775 (98%)]	Loss: 2.722032

Train Epoch: 2 [3840/11775 (33%)]	Loss: 2.720056
Train Epoch: 2 [7680/11775 (65%)]	Loss: 2.715218
Train Epoch: 2 [11520/11775 (98%)]	Loss: 2.711617

Train Epoch: 3 [3840/11775 (33%)]	Loss: 2.700235
Train Epoch: 3 [7680/11775 (65%)]	Loss: 2.692197
Train Epoch: 3 [11520/11775 (98%)]	Loss: 2.679172

Train Epoch: 4 [3840/11775 (33%)]	Loss: 2.673524
Train Epoch: 4 [7680/11775 (65%)]	Loss: 2.654811
Train Epoch: 4 [11520/11775 (98%)]	Loss: 2.638573

Train Epoch: 5 [3840/11775 (33%)]	Loss: 2.610524
Train Epoch: 5 [7680/11775 (65%)]	Loss: 2.577014
Train Epoch: 5 [11520/11775 (98%)]	Loss: 2.535411

Train Epoch: 6 [3840/11775 (33%)]	Loss: 2.480640
Train Epoch: 6 [7680/11775 (65%)]	Loss: 2.447208
Train Epoch: 6 [11520/11775 (98%)]	Loss: 2.396198

Train Epoch: 7 [3840/11775 (33%)]	Loss: 2.349235
Train Epoch: 7 [7680/11775 (65%)]	Loss: 2.300546
Train Epoch: 7 [11520/11775 (98%)]	Loss: 2.256376

Train Epoch: 8 [3840/11775 (33%)]	Loss: 2.208190
Train Epoch: 8 [7680/11775 (65%)]	Loss: 2.162754
Train Epoch: 8 [11520/11775 (98%)]	Loss: 2.123852

Train Epoch: 9 [3840/11775 (33%)]	Loss: 2.085609
Train Epoch: 9 [7680/11775 (65%)]	Loss: 2.037354
Train Epoch: 9 [11520/11775 (98%)]	Loss: 1.996239

/home/raccooncoder/.venv/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`

Test set: Average loss: 1.9845, Average CER: 0.819052 Average WER: 0.7301

Train Epoch: 10 [3840/11775 (33%)]	Loss: 1.962288
Train Epoch: 10 [7680/11775 (65%)]	Loss: 1.933876
Train Epoch: 10 [11520/11775 (98%)]	Loss: 1.893872

Train Epoch: 11 [3840/11775 (33%)]	Loss: 1.865549
Train Epoch: 11 [7680/11775 (65%)]	Loss: 1.836757
Train Epoch: 11 [11520/11775 (98%)]	Loss: 1.797105

Train Epoch: 12 [3840/11775 (33%)]	Loss: 1.768521
Train Epoch: 12 [7680/11775 (65%)]	Loss: 1.733432
Train Epoch: 12 [11520/11775 (98%)]	Loss: 1.713275

Train Epoch: 13 [3840/11775 (33%)]	Loss: 1.681378
Train Epoch: 13 [7680/11775 (65%)]	Loss: 1.651640
Train Epoch: 13 [11520/11775 (98%)]	Loss: 1.639394

Train Epoch: 14 [3840/11775 (33%)]	Loss: 1.601664
Train Epoch: 14 [7680/11775 (65%)]	Loss: 1.571738
Train Epoch: 14 [11520/11775 (98%)]	Loss: 1.554454

Train Epoch: 15 [3840/11775 (33%)]	Loss: 1.541300
Train Epoch: 15 [7680/11775 (65%)]	Loss: 1.511347
Train Epoch: 15 [11520/11775 (98%)]	Loss: 1.497857

Train Epoch: 16 [3840/11775 (33%)]	Loss: 1.468365
Train Epoch: 16 [7680/11775 (65%)]	Loss: 1.465344
Train Epoch: 16 [11520/11775 (98%)]	Loss: 1.450949

Train Epoch: 17 [3840/11775 (33%)]	Loss: 1.424802
Train Epoch: 17 [7680/11775 (65%)]	Loss: 1.411680
Train Epoch: 17 [11520/11775 (98%)]	Loss: 1.386171

Train Epoch: 18 [3840/11775 (33%)]	Loss: 1.372514
Train Epoch: 18 [7680/11775 (65%)]	Loss: 1.368865
Train Epoch: 18 [11520/11775 (98%)]	Loss: 1.354431

Train Epoch: 19 [3840/11775 (33%)]	Loss: 1.340550
Train Epoch: 19 [7680/11775 (65%)]	Loss: 1.338314
Train Epoch: 19 [11520/11775 (98%)]	Loss: 1.314989


Test set: Average loss: 1.3144, Average CER: 0.423297 Average WER: 0.4419

Train Epoch: 20 [3840/11775 (33%)]	Loss: 1.308686
Train Epoch: 20 [7680/11775 (65%)]	Loss: 1.286478
Train Epoch: 20 [11520/11775 (98%)]	Loss: 1.282074

Train Epoch: 21 [3840/11775 (33%)]	Loss: 1.259511
Train Epoch: 21 [7680/11775 (65%)]	Loss: 1.262951
Train Epoch: 21 [11520/11775 (98%)]	Loss: 1.250131

Train Epoch: 22 [3840/11775 (33%)]	Loss: 1.235231
Train Epoch: 22 [7680/11775 (65%)]	Loss: 1.232034
Train Epoch: 22 [11520/11775 (98%)]	Loss: 1.212745

Train Epoch: 23 [3840/11775 (33%)]	Loss: 1.217079
Train Epoch: 23 [7680/11775 (65%)]	Loss: 1.206073
Train Epoch: 23 [11520/11775 (98%)]	Loss: 1.189325

Train Epoch: 24 [3840/11775 (33%)]	Loss: 1.180453
Train Epoch: 24 [7680/11775 (65%)]	Loss: 1.173239
Train Epoch: 24 [11520/11775 (98%)]	Loss: 1.161094

Train Epoch: 25 [3840/11775 (33%)]	Loss: 1.150701
Train Epoch: 25 [7680/11775 (65%)]	Loss: 1.144281
Train Epoch: 25 [11520/11775 (98%)]	Loss: 1.135262

Train Epoch: 26 [3840/11775 (33%)]	Loss: 1.128864
Train Epoch: 26 [7680/11775 (65%)]	Loss: 1.121388
Train Epoch: 26 [11520/11775 (98%)]	Loss: 1.124003

Train Epoch: 27 [3840/11775 (33%)]	Loss: 1.100304
Train Epoch: 27 [7680/11775 (65%)]	Loss: 1.098615
Train Epoch: 27 [11520/11775 (98%)]	Loss: 1.093593

Train Epoch: 28 [3840/11775 (33%)]	Loss: 1.082569
Train Epoch: 28 [7680/11775 (65%)]	Loss: 1.078408
Train Epoch: 28 [11520/11775 (98%)]	Loss: 1.073134

Train Epoch: 29 [3840/11775 (33%)]	Loss: 1.063997
Train Epoch: 29 [7680/11775 (65%)]	Loss: 1.060058
Train Epoch: 29 [11520/11775 (98%)]	Loss: 1.053346


Test set: Average loss: 1.0632, Average CER: 0.332478 Average WER: 0.3653

Train Epoch: 30 [3840/11775 (33%)]	Loss: 1.045193
Train Epoch: 30 [7680/11775 (65%)]	Loss: 1.037262
Train Epoch: 30 [11520/11775 (98%)]	Loss: 1.037132

Train Epoch: 31 [3840/11775 (33%)]	Loss: 1.027665
Train Epoch: 31 [7680/11775 (65%)]	Loss: 1.019541
Train Epoch: 31 [11520/11775 (98%)]	Loss: 1.010437

Train Epoch: 32 [3840/11775 (33%)]	Loss: 1.010167
Train Epoch: 32 [7680/11775 (65%)]	Loss: 1.008248
Train Epoch: 32 [11520/11775 (98%)]	Loss: 0.999730

Train Epoch: 33 [3840/11775 (33%)]	Loss: 0.998294
Train Epoch: 33 [7680/11775 (65%)]	Loss: 0.993250
Train Epoch: 33 [11520/11775 (98%)]	Loss: 0.994450

Train Epoch: 34 [3840/11775 (33%)]	Loss: 0.982491
Train Epoch: 34 [7680/11775 (65%)]	Loss: 0.980140
Train Epoch: 34 [11520/11775 (98%)]	Loss: 0.974525

Train Epoch: 35 [3840/11775 (33%)]	Loss: 0.959195
Train Epoch: 35 [7680/11775 (65%)]	Loss: 0.961028
Train Epoch: 35 [11520/11775 (98%)]	Loss: 0.946840

Train Epoch: 36 [3840/11775 (33%)]	Loss: 0.944805
Train Epoch: 36 [7680/11775 (65%)]	Loss: 0.942195
Train Epoch: 36 [11520/11775 (98%)]	Loss: 0.945735

Train Epoch: 37 [3840/11775 (33%)]	Loss: 0.936024
Train Epoch: 37 [7680/11775 (65%)]	Loss: 0.931398
Train Epoch: 37 [11520/11775 (98%)]	Loss: 0.930520

Train Epoch: 38 [3840/11775 (33%)]	Loss: 0.920707
Train Epoch: 38 [7680/11775 (65%)]	Loss: 0.925577
Train Epoch: 38 [11520/11775 (98%)]	Loss: 0.920888

Train Epoch: 39 [3840/11775 (33%)]	Loss: 0.917930
Train Epoch: 39 [7680/11775 (65%)]	Loss: 0.912854
Train Epoch: 39 [11520/11775 (98%)]	Loss: 0.907287


Test set: Average loss: 0.9220, Average CER: 0.297440 Average WER: 0.3271

Train Epoch: 40 [3840/11775 (33%)]	Loss: 0.901260
Train Epoch: 40 [7680/11775 (65%)]	Loss: 0.905941
Train Epoch: 40 [11520/11775 (98%)]	Loss: 0.894832

Train Epoch: 41 [3840/11775 (33%)]	Loss: 0.893830
Train Epoch: 41 [7680/11775 (65%)]	Loss: 0.891670
Train Epoch: 41 [11520/11775 (98%)]	Loss: 0.886226

Train Epoch: 42 [3840/11775 (33%)]	Loss: 0.875082
Train Epoch: 42 [7680/11775 (65%)]	Loss: 0.878152
Train Epoch: 42 [11520/11775 (98%)]	Loss: 0.873960

Train Epoch: 43 [3840/11775 (33%)]	Loss: 0.866738
Train Epoch: 43 [7680/11775 (65%)]	Loss: 0.856085
Train Epoch: 43 [11520/11775 (98%)]	Loss: 0.867740

Train Epoch: 44 [3840/11775 (33%)]	Loss: 0.866506
Train Epoch: 44 [7680/11775 (65%)]	Loss: 0.862123
Train Epoch: 44 [11520/11775 (98%)]	Loss: 0.845690

Train Epoch: 45 [3840/11775 (33%)]	Loss: 0.847277
Train Epoch: 45 [7680/11775 (65%)]	Loss: 0.841942
Train Epoch: 45 [11520/11775 (98%)]	Loss: 0.841772

Train Epoch: 46 [3840/11775 (33%)]	Loss: 0.835500
Train Epoch: 46 [7680/11775 (65%)]	Loss: 0.852861
Train Epoch: 46 [11520/11775 (98%)]	Loss: 0.831293

Train Epoch: 47 [3840/11775 (33%)]	Loss: 0.831354
Train Epoch: 47 [7680/11775 (65%)]	Loss: 0.840652
Train Epoch: 47 [11520/11775 (98%)]	Loss: 0.837167

Train Epoch: 48 [3840/11775 (33%)]	Loss: 0.824877
Train Epoch: 48 [7680/11775 (65%)]	Loss: 0.821712
Train Epoch: 48 [11520/11775 (98%)]	Loss: 0.818659

Train Epoch: 49 [3840/11775 (33%)]	Loss: 0.817939
Train Epoch: 49 [7680/11775 (65%)]	Loss: 0.813619
Train Epoch: 49 [11520/11775 (98%)]	Loss: 0.812772


Test set: Average loss: 0.8219, Average CER: 0.276975 Average WER: 0.3090

Example 0:
dtestifid that the sir and other riing o the aplicationt rethat bokxerin the hadradyng ofle arvik sal
------------------------------------
testified that the signature and other writing on the application for that box were in the handwriting of lee harvey oswald

Example 1:
thi shioferstapprd in the dev onin and upersilorian in vary ratilin orather emfimian foars
------------------------------------
fishes first appeared in the devonian and upper silurian in very reptilian or rather amphibian forms

Example 2:
to caliunderd extra oftduty officers to hup fortect president kenedy
------------------------------------
to call in one hundred extra offduty officers to help protect president kennedy

Example 3:
as tin passt
------------------------------------
as time passed

Example 4:
in vuovespeking toet at the tril ind hecud esealy dur orvhery baco
------------------------------------
in view of speaking to it at the trial and he could easily do them a good turn  or a very bad one

Example 5:
camdecteser vhas agenceinforaort a novembeqentytwoe
------------------------------------
conduct of secret service agents in fort worth on november twentytwo

Example 6:
i prisoner baxter ispfirmery in consequence of a sevear inury to his ris jomts
------------------------------------
a prisoner baxter is in the infirmary in consequence of a severe injury to his wristjoint

Example 7:
gave mor peple an apersipit
------------------------------------
gave more people an opportunity to participate

Example 8:
the tititexis began wath the depratur of president and miisehat has
------------------------------------
the trip to texas began with the departure of president and mrs kennedy from the white house

Example 9:
the matter re aghte pense almo them topa for atrusofstrafor the porwemen to lion
------------------------------------
the latter raised eighteen pence among them to pay for a truss of straw for the poor woman to lie on

/home/raccooncoder/.venv/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  
Train Epoch: 0 [3840/11775 (33%)]	Loss: 0.803145
Train Epoch: 0 [7680/11775 (65%)]	Loss: 0.797282
Train Epoch: 0 [11520/11775 (98%)]	Loss: 0.805713

Train Epoch: 1 [3840/11775 (33%)]	Loss: 0.792587
Train Epoch: 1 [7680/11775 (65%)]	Loss: 0.791729
Train Epoch: 1 [11520/11775 (98%)]	Loss: 0.783279

Train Epoch: 2 [3840/11775 (33%)]	Loss: 0.786244
Train Epoch: 2 [7680/11775 (65%)]	Loss: 0.784346
Train Epoch: 2 [11520/11775 (98%)]	Loss: 0.786523

Train Epoch: 3 [3840/11775 (33%)]	Loss: 0.782747
Train Epoch: 3 [7680/11775 (65%)]	Loss: 0.780237
Train Epoch: 3 [11520/11775 (98%)]	Loss: 0.771168

Train Epoch: 4 [3840/11775 (33%)]	Loss: 0.768906
Train Epoch: 4 [7680/11775 (65%)]	Loss: 0.765407
Train Epoch: 4 [11520/11775 (98%)]	Loss: 0.765658

Train Epoch: 5 [3840/11775 (33%)]	Loss: 0.761936

